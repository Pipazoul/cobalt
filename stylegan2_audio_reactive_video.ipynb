{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stylegan2_audio_reactive_video",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# StyleGan2 Audio Reactive\n",
        "\n",
        "This notebook can be used to generate stylegan2 video based on audio layers\n",
        "\n",
        "Author : [@sioudayassin](https://twitter.com/SioudaYassin)\n",
        "\n",
        "The latent generation code is from [@robertluxemburg](https://twitter.com/robertluxemburg)\n",
        "\n",
        "\n",
        "\n",
        "License : [CC BY-NC 4.0 ](https://creativecommons.org/licenses/by-nc/4.0/deed.fr)\n",
        "\n",
        "\n",
        "**Main Libs used :**\n",
        "- [StyleGan2](https://github.com/NVlabs/stylegan)\n",
        "- [Spleeter](https://github.com/deezer/spleeter) \n",
        "\n",
        "\n",
        "\n",
        "# **READ CAREFULLY BEFORE LAUNCHING**\n",
        "\n",
        "To use the generator you will have to host the model files by yourself on Google Drive\n",
        "\n",
        "Once uploaded modify the cell **Double click me to add the path to your model files** by adding Google drive path to your file\n",
        "\n",
        "\n",
        "\n",
        "Here you can find the download links to those used in this collab :\n",
        "\n",
        "\n",
        "**Flickr Faces**\n",
        "\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2\n",
        "\n",
        "- Download : http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-e.pkl\n",
        "\n",
        "**Cats**\n",
        "\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2\n",
        "\n",
        "- Download : http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-cat-config-f.pkl\n",
        "\n",
        "\n",
        "\n",
        "**Abstract Art**\n",
        "\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2\n",
        "\n",
        "- Download : https://drive.google.com/uc?id=1YzZemZAp7BVW701_BZ7uabJWJJaS2g7v\n",
        "\n",
        "\n",
        "**Fursonna**\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2\n",
        "- Download : https://thisfursonadoesnotexist.com/model/network-e621-r-512-3194880.pkl\n",
        "\n",
        "\n",
        "**Painting Faces**\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2#faces-FFHQ-config-f-512x512\n",
        "- Download : https://drive.google.com/uc?id=1H-MYFZqngF1R0whm4bc3fEoX7VvOWaDl\n",
        "\n",
        "\n",
        "**Ukiyoe faces**\n",
        "- Repo : https://github.com/justinpinkney/awesome-pretrained-stylegan2#faces-FFHQ-config-f-512x512\n",
        "- Download : https://drive.google.com/uc?id=1_QysUKfed1-_x9e5off2WWJKp1yUcidu\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czZUuG6HOkrH"
      },
      "source": [
        "# Audio Reactive Style GAN 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlNALEZ_OkdQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT"
      },
      "source": [
        "#@title #**Setup stylegan requirements** { display-mode: \"form\" }\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "!pip install -U kora\n",
        "from kora.drive import upload_public\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "!pip install wget\n",
        "!mkdir model\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "#!pip install spotdl==3.3.1\n",
        "\n",
        "!curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl\n",
        "!chmod a+rx /usr/local/bin/youtube-dl\n",
        "\n",
        "\n",
        "!apt install ffmpeg\n",
        "\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))\n",
        "\n",
        "!cd /content/stylegan2\n",
        "\n",
        "!mkdir data\n",
        "\n",
        "\n",
        "#https://rolux.org/media/stylegan2/vectors/mouth_ratio.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/mouth_ratio.npy -O data/mouth_ratio.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/eye_open.npy -O data/eye_open.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/pitch.npy -O data/pitch.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/gender.npy -O data/gender.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/smile.npy -O data/smil.e.npy\n",
        "!wget https://rolux.org/media/stylegan2/vectors/age.npy -O data/age.npy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmLBMLg7Ifg"
      },
      "source": [
        "# Mount your google drive account\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADAmc5lc7F6z"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CoqYquB0Or5"
      },
      "source": [
        "## Load Model urls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6BpjLVs7Obe"
      },
      "source": [
        "#@title #**Double click me to add the path to your model files** \n",
        "models = {}\n",
        "models['flikr_faces'] = '/content/drive/My Drive/Colab Notebooks/stylegan/models/eurorack_modules/eurorack_modules_v2_1024.pkl'  \n",
        "models['abstract_art'] = '/content/drive/My Drive/PathToMyModel'  \n",
        "models['figure_drawing'] = '/content/drive/My Drive/PathToMyModel' \n",
        "models['floor_plans'] = '/content/drive/My Drive/PathToMyModel' \n",
        "models['fursona'] = '/content/drive/My Drive/PathToMyModel'  \n",
        "models['cats'] = '/content/drive/My Drive/PathToMyModel'  \n",
        "models['celebrities'] = '/content/drive/My Drive/PathToMyModel'  \n",
        "models['painting_face'] = '/content/drive/My Drive/PathToMyModel' \n",
        "models['ukiyoe_faces'] = '/content/drive/My Drive/PathToMyModel'  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRnVQQqD0Rci"
      },
      "source": [
        "#@title #**Model selector** { run: \"auto\", display-mode: \"form\" }\n",
        "# Download the model of choice\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "import wget\n",
        "import pretrained_networks\n",
        "import os\n",
        "import random\n",
        "model_selector = \"flikr_faces\"  #@param ['ukiyoe_faces','painting_face','celebrities','cats','flikr_faces','abstract_art','figure_drawing','floor_plans','fursona']\n",
        " \n",
        "print(model_selector)\n",
        " \n",
        "network_pkl = models[model_selector]\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Gs_kwargs = dnnlib.EasyDict()\n",
        "Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_kwargs.randomize_noise = False\n",
        " \n",
        "seed = random.randint(0, 5000000)\n",
        "truncation_psi = 0.5\n",
        "Gs_kwargs.truncation_psi = truncation_psi\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "#print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n",
        "rnd = np.random.RandomState(seed)\n",
        "z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "PIL.Image.fromarray(images[0], 'RGB').save(str(seed) + '.png')\n",
        " \n",
        "isp = IPython.display.display(IPython.display.Image(str(seed) + '.png'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9a3X_Hv0WBW"
      },
      "source": [
        "## Download a music trough youtube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2iPWCyX0ZbE"
      },
      "source": [
        "#@title #**Music url** {display-mode: \"form\" }\n",
        "import os\n",
        "musciUrl =  'https://youtu.be/i23NEQEFpgQ' #@param {type: \"string\"}\n",
        "os.environ['MUSIC_URL'] = musciUrl\n",
        "\n",
        "#!spotdl -s $MUSIC_URL \n",
        "!youtube-dl --extract-audio --audio-format mp3 $MUSIC_URL --output \"/content/stylegan2/data/input.%(ext)s\"\n",
        "\n",
        "'''url = upload_public('/content/stylegan2/data/input.mp3')'''\n",
        "# then display it\n",
        "from IPython.display import HTML\n",
        "\n",
        "#HTML(f\"\"\" {url} \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9aawIJK4A6r"
      },
      "source": [
        "#@title #**For test purpose time range audio preview** { display-mode: \"form\" }\n",
        "#@markdown shorten video rendering to 10-20 seconds to reduce the video rendering wait time .\n",
        "\n",
        "start_timecode = '00:00:40'  #@param {type: \"string\"}\n",
        "end_timecode = '00:01:00'  #@param {type: \"string\"}\n",
        "\n",
        "os.environ['START_TIMECODE'] = start_timecode\n",
        "os.environ['END_TIMECODE'] = end_timecode\n",
        "\n",
        "\n",
        "!ffmpeg -i /content/stylegan2/data/input.mp3 -ss $START_TIMECODE -to $END_TIMECODE -c copy /content/stylegan2/data/input_preview.mp3\n",
        "!rm /content/stylegan2/data/input.mp3\n",
        "!mv /content/stylegan2/data/input_preview.mp3 /content/stylegan2/data/input.mp3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtavF9UThkm"
      },
      "source": [
        "#@title #**Install Spleeter** { display-mode: \"form\" }\n",
        "!pip install spleeter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF2kahTB9hkB"
      },
      "source": [
        "#@title #**Split the audio into tracks with Spleeter** { display-mode: \"form\" }\n",
        "!rm /content/stylegan2/data/input.wav\n",
        "!spleeter separate  -o /content/stylegan2/data/ -p spleeter:5stems /content/stylegan2/data/input.mp3\n",
        "!mv /content/stylegan2/data/input/* /content/stylegan2/data\n",
        "!ffmpeg -i /content/stylegan2/data/input.mp3 /content/stylegan2/data/input.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQqk-EXfLHYx"
      },
      "source": [
        "#@title #**Audio Processing** { display-mode: \"form\" }\n",
        "# git clone https://github.com/NVlabs/stylegan2\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.io import wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import moviepy.editor\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import pretrained_networks\n",
        "\n",
        "import collections \n",
        "\n",
        "audio = {}\n",
        "fps = 24\n",
        "\n",
        "\n",
        "# https://www.google.com/search?q=death+grips+black+google+download\n",
        "for mp3_filename in [f for f in os.listdir('data') if f.endswith('.wav')]:\n",
        "    mp3_filename = f'data/{mp3_filename}'\n",
        "    wav_filename = mp3_filename\n",
        "    if not os.path.exists(wav_filename):\n",
        "        audio_clip = moviepy.editor.AudioFileClip(mp3_filename)\n",
        "        audio_clip.write_audiofile(wav_filename, fps=44100, nbytes=2, codec='pcm_s16le')\n",
        "    track_name = os.path.basename(wav_filename).split(\".\")[0]\n",
        "    print(track_name)\n",
        "    rate, signal = wavfile.read(wav_filename)\n",
        "    signal = np.mean(signal, axis=1) # to mono\n",
        "    signal = np.abs(signal)\n",
        "    seed = signal.shape[0]\n",
        "    duration = signal.shape[0] / rate\n",
        "    frames = int(np.ceil(duration * fps))\n",
        "    samples_per_frame = signal.shape[0] / frames\n",
        "    audio[track_name] = np.zeros(frames, dtype=signal.dtype)\n",
        "    #print( audio[track_name])\n",
        "    for frame in range(frames):\n",
        "        start = int(round(frame * samples_per_frame))\n",
        "        stop = int(round((frame + 1) * samples_per_frame))\n",
        "        audio[track_name][frame] = np.mean(signal[start:stop], axis=0)\n",
        "    audio[track_name] /= max(audio[track_name])\n",
        "\n",
        "\n",
        "for track in sorted(audio.keys()):\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.title(track)\n",
        "    plt.plot(audio[track])\n",
        "    plt.savefig(f'data/{track}.png')\n",
        "\n",
        "#network_pkl = '/content/drive/My Drive/Colab Notebooks/stylegan/models/StyleGAN2_microscopev1.pkl'\n",
        "#_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "\n",
        "Gs_kwargs = dnnlib.EasyDict()\n",
        "Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_kwargs.randomize_noise = False\n",
        "Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_syn_kwargs.randomize_noise = False\n",
        "Gs_syn_kwargs.minibatch_size = 4\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "w_avg = Gs.get_var('dlatent_avg')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu3kx7ZEaXA6"
      },
      "source": [
        "## Check the seperate audio tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4oD-GROU37N"
      },
      "source": [
        "#@title #**Listen to the input track** { display-mode: \"form\" }\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "Audio('/content/stylegan2/data/input.wav')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TADe-UhqStWQ"
      },
      "source": [
        "#@title #**Listen to the bass track** { display-mode: \"form\" }\n",
        "Audio('/content/stylegan2/data/bass.wav')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga7dL446USxV"
      },
      "source": [
        "#@title #**Listen to the drums track** { display-mode: \"form\" }\n",
        "Audio('/content/stylegan2/data/drums.wav')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYl-8wLZUU5t"
      },
      "source": [
        "#@title #**Listen to the piano track** { display-mode: \"form\" }\n",
        "Audio('/content/stylegan2/data/piano.wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJSCN1QUWFh"
      },
      "source": [
        "#@title #**Listen to the vocals track** { display-mode: \"form\" }\n",
        "Audio('/content/stylegan2/data/vocals.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0MNXFQhUyCc"
      },
      "source": [
        "#@title #**Listen to the other track** { display-mode: \"form\" }\n",
        "\n",
        "Audio('/content/stylegan2/data/other.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhqhHmoOqf3F"
      },
      "source": [
        "#@title #**NOT STATIC Video Generation - multiple channel -  Faces (master)** { display-mode: \"form\" }\n",
        "#@markdown if your model is based on faces you can control the facial features as parameters, can also be used with models not containing faces \n",
        "# base_index\n",
        "# psi\n",
        "#psiValue = \"vocals\" #@param ['bass', 'drums','piano','vocals','other','microscopev1','cats', 'toplessgan_female', 'dicks_v3', 'fursona', 'family', 'modules_v2_faces', 'eye_makeup']\n",
        "EnableMouth_open = True #@param {type:\"boolean\"}\n",
        "mouth_openFactor = 1.2  #@param {type: \"slider\", min: 0.2, max: 2, step : 0.2}\n",
        "EnableEye_open = True #@param {type:\"boolean\"}\n",
        "eye_openFactor = 1.4  #@param {type: \"slider\", min: 0.2, max: 2, step : 0.2}\n",
        "EnablePitch = True #@param {type:\"boolean\"}\n",
        "pitchFactor = 1.4  #@param {type: \"slider\", min: 0.2, max: 2, step : 0.2}\n",
        "EnableSmile = False #@param {type:\"boolean\"}\n",
        "#@markdown (not audio reactive - fixed in timeline parameter)\n",
        "smileFactor = 0.6  #@param {type: \"slider\", min: 0.2, max: 2, step : 0.2}\n",
        "\n",
        "EnableAge = False #@param {type:\"boolean\"}\n",
        "ageFactor = 0.6  #@param {type: \"slider\", min: 0.2, max: 2, step : 0.2}\n",
        "\n",
        "\n",
        "psi = 0.1  #@param {type: \"slider\", min: 0.1, max: 2, step : 0.2}\n",
        "\n",
        "\n",
        "!rm \"/content/stylegan2/data/outputPreview.mp4\"\n",
        "!rm \"/content/stylegan2/data/output.mp4\"\n",
        "\n",
        "def get_ws(n, frames, seed):\n",
        "    filename = f'data/ws_{n}_{frames}_{seed}.npy'\n",
        "    if not os.path.exists(filename):\n",
        "        src_ws = np.random.RandomState(seed).randn(n, 512)\n",
        "        ws = np.empty((frames, 512))\n",
        "        for i in range(512):\n",
        "            # FIXME: retarded\n",
        "            x = np.linspace(0, 3*frames, 3*len(src_ws), endpoint=False)\n",
        "            y = np.tile(src_ws[:, i], 3)\n",
        "            x_ = np.linspace(0, 3*frames, 3*frames, endpoint=False)\n",
        "            y_ = interp1d(x, y, kind='quadratic', fill_value='extrapolate')(x_)\n",
        "            ws[:, i] = y_[frames:2*frames]\n",
        "        np.save(filename, ws)\n",
        "    else:\n",
        "        ws = np.load(filename)\n",
        "    return ws\n",
        "\n",
        "def mix_styles(wa, wb, ivs):\n",
        "    w = np.copy(wa)\n",
        "    for i, v in ivs:\n",
        "        w[i] = wa[i] * (1 - v) + wb[i] * v\n",
        "    return w\n",
        "\n",
        "def normalize_vector(v):\n",
        "    return v * np.std(w_avg) / np.std(v) + np.mean(w_avg) - np.mean(v)\n",
        "\n",
        "def render_frame(t):\n",
        "    #print(audio)\n",
        "    global base_index\n",
        "    frame = np.clip(np.int(np.round(t * fps)), 0, frames - 1)\n",
        "    base_index += base_speed * audio['drums'][frame]**2\n",
        "    #base_index += base_speed\n",
        "    #base_index += base_speed\n",
        "    base_w = base_ws[int(round(base_index)) % len(base_ws)]\n",
        "    base_w = np.tile(base_w, (18, 1))\n",
        "    psi = 0.5 + audio['bass'][frame] / 2\n",
        "    #psi = 0.5\n",
        "    base_w = w_avg + (base_w - w_avg) * psi\n",
        "    mix_w = np.tile(mix_ws[frame], (18, 1))\n",
        "    mix_w = w_avg + (mix_w - w_avg) * 0.75\n",
        "    ranges = [range(0, 4), range(4, 8), range(8, 18)]\n",
        "    values = [audio[track][frame] for track in ['vocals', 'bass', 'drums', 'other']]\n",
        "    w = mix_styles(base_w, mix_w, zip(ranges, values))\n",
        "    if EnableMouth_open :\n",
        "      w += mouth_open * audio['vocals'][frame] * mouth_openFactor\n",
        "    if EnablePitch:\n",
        "      w += pitch * audio['drums'][frame] * pitchFactor * audio['bass'][frame]\n",
        "    if EnableEye_open :\n",
        "      w += eye_open * audio['bass'][frame] * eye_openFactor * audio['drums'][frame]\n",
        "    #w += gender+0.2\n",
        "    if EnableSmile :\n",
        "      w += smileFactor\n",
        "    if EnableAge :\n",
        "      w += age * audio['bass'][frame] * ageFactor\n",
        "    image = Gs.components.synthesis.run(np.stack([w]), **Gs_syn_kwargs)[0]\n",
        "    image = PIL.Image.fromarray(image).resize((size, size), PIL.Image.LANCZOS)\n",
        "    return np.array(image)\n",
        "    \n",
        "size = 512\n",
        "seconds = int(np.ceil(duration))\n",
        "resolution = 10\n",
        "base_frames = resolution * frames\n",
        "base_ws = get_ws(seconds, base_frames, seed)\n",
        "base_speed = base_frames / sum(audio['drums']**2)\n",
        "#base_speed = 0\n",
        "base_index = 0\n",
        "mix_ws = get_ws(seconds, frames, seed + 1)\n",
        "# https://rolux.org/media/stylegan2/vectors/mouth_ratio.npy\n",
        "!\n",
        "mouth_open = normalize_vector(-np.load('data/mouth_ratio.npy'))\n",
        "pitch = normalize_vector(-np.load('data/pitch.npy'))\n",
        "eye_open = normalize_vector(-np.load('data/eye_open.npy'))\n",
        "gender = normalize_vector(-np.load('data/gender.npy'))\n",
        "#smile = normalize_vector(-np.load('data/smile.npy'))\n",
        "age = normalize_vector(-np.load('data/age.npy'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mp4_filename = 'data/output.mp4'\n",
        "video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n",
        "#audio_clip_i = moviepy.editor.AudioFileClip('data/input.wav')\n",
        "audio_clip_v = moviepy.editor.AudioFileClip('data/input.wav')\n",
        "audio_clip = moviepy.editor.CompositeAudioClip([audio_clip_v])\n",
        "video_clip = video_clip.set_audio(audio_clip)\n",
        "video_clip.write_videofile(mp4_filename, fps=fps, codec='libx264', audio_codec='aac', bitrate='8M')\n",
        "\n",
        "\n",
        "\n",
        "!ffmpeg -i /content/stylegan2/data/output.mp4 -b 1000000 -y /content/stylegan2/data/outputPreview.mp4\n",
        "\n",
        "\n",
        "\n",
        "'''url = upload_public('/content/stylegan2/data/outputPreview.mp4')\n",
        "# then display it\n",
        "from IPython.display import HTML\n",
        "HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")\n",
        "'''\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/stylegan2/data/outputPreview.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpx6dj-bBv4B"
      },
      "source": [
        "#@title #**Clean workspace (data folder)** { display-mode: \"form\" }\n",
        "!rm -r /content/stylegan2/data/*.wav\n",
        "!rm -r /content/stylegan2/data/*.mp3\n",
        "!rm -r /content/stylegan2/data/*.png\n",
        "!rm -r /content/stylegan2/data/*.mp4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}